---
title: "Week 11 Demonstration"
format: html
editor: visual
---

## Set up

```{r}
#| message: FALSE
library(fpp3)
library(tidyverse)
library(slider)
library(gridExtra)
```

## 1. Unit root tests

Load the sunspots data via the following code snippet.

```{r}
sunspots <- readRDS("../_data/cleaned/sunspots.rds")
```

a.  Before running the tests, do you expect the ADF test to have a small or big p-value?

b.  Before running the tests, do you expect the KPSS test to have a small or big p-value?

c.  Run the ADF test using `adf.test` and interpret the results.

d.  Run the KPSS test using `kpss.test` and interpret the results.

e.  What do the warnings in the test print out mean?

------------------------------------------------------------------------

a.  Let us first plot the time series

```{r}
sunspots |> autoplot(Sunspots)
```

The time series looks stationary. Hence, we expect the ADF test to have a relatively small p-value (we reject the null hypothesis that a unit root exists), and the KPSS test to have a relatively large p-value (we do not reject the null hypothesis that the time series is stationary).

```{r}
library(tseries)
sunspots$Sunspots |> adf.test()
```

We indeed get a small p-value.

```{r}
sunspots$Sunspots |> kpss.test()
```

We indeed get a relatively large p-value.

The warnings are that the true p-value is different from the printed p-value. This is because the printed p-values are computed by interpolating values from a table.

------------------------------------------------------------------------

## 2. ARIMA and the intercept term

a.  Fit an ARIMA model to the sunspots data. What model orders were chosen?

b.  Inspect the constant term parameter. Is it equal to the mean of the time series? If not, how is it related to the mean?

c.  If $(X_t)$ is ARIMA with $d=1$, how is the constant term related to the slope of the forecast curve?

d.  If $(X_t)$ is ARIMA with $d=2$, how is the constant term related to the curvature of the forecast curve?

e.  If $(X_t)$ is ARIMA with $d=2$, what happens when the constant term is equal to 0?

------------------------------------------------------------------------

```{r}
sunspots_fit <- sunspots |>
  model(ARIMA(Sunspots))
sunspots_fit
```

The chosen model is ARMA(2,1) with a constant term.

```{r}
sunspots_fit |> tidy()
```

The constant term is 22.96. This is clearly not the mean of the time series. Instead, it appears in the equation as

$$
X_t = 1.48X_{t-1} -0.77X_{t-2} - 0.19W_t + 22.96
$$

To mean is

$$
\mu = \frac{\alpha}{1-\phi_1-\phi_2} = \frac{22.96}{1 - 1.48 + 0.77} \approx 79.17
$$

If $d=1$, then $Y_t = (I-B)X_t$ is stationary, with mean satisfying $\mu = \alpha/(1-\phi_1-\cdots\phi_p)$.

The forecast satisfies

$$
\hat X_{n+t|n} = X_n + \hat Y_{n+1|n} + \hat Y_{n+2|n} + \cdots + \hat Y_{n+t|n}.
$$

Now, since $\lim_{t \to \infty} \hat Y_{n+t|n} = \mu$, we see that $\hat X_{n+t|n} \approx X_n + t\mu$ for $t$ large enough. Hence, the slope of the forecast curve is approximately $\mu$.

If $d=2$, then $Y_t = (I-B)^2X_t$ is stationary, with mean satisfying $\mu = \alpha/(1-\phi_1-\cdots\phi_p)$.

Let $Z_t = (I-B)X_t$. Using the argument from before, we have $\hat Z_{n+t|n} \approx Z_n + t\mu$ for $t$ large enough. We then write

The forecast satisfies

$$
\begin{split}
\hat X_{n+t|n} & = X_n + \hat Z_{n+1|n} + \hat Z_{n+2|n} + \cdots + \hat Z_{n+t|n} \\
& \approx X_n + (Z_n + \mu) + (Z_n + 2\mu) + \cdots (Z_n + t\mu) \\
& = X_n + tZ_n + \frac{t^2}{2}\mu.
\end{split}
$$

Hence, the curvature of the forecast curve is equal to $\mu$.

If $d = 2, \mu = 0$, then the forecast curve has no curvature, i.e. it converges to a straight line. However, the slope of this line is not fixed, and depends on the observed values.

------------------------------------------------------------------------

## 3. Stochastic vs deterministic trends

We have seen two methods of modeling trends:

(i) Deterministic trend: $X_t = Y_t + \beta_0 + \beta_1 t$, where $Y_t$ is ARMA (stationary)
(ii) Stochastic trend: $(I-B)X_t$ is ARMA, i.e. $X_t$ is ARIMA(p, 1, q) for some $p$ and $q$.

In this question, we explore their differences, using the dataset `aus_airpassengers`.

a.  Fit a deterministic trend model to the time series. What are the model parameters? Write out the modeling equation(s).

b.  Fit a stochastic trend model to the time series. What are the model parameters? Write out the modeling equation(s).

c.  Compare the two sets of modeling equations.

d.  How do their forecasts differ?

e.  When should you use a stochastic trend instead of a deterministic trend?

------------------------------------------------------------------------

```{r}
deterministic_fit <- aus_airpassengers |>
  model(deterministic = ARIMA(Passengers ~ trend() + 1 + pdq(d = 0)))

deterministic_fit |>
  report()
```

We have

$$
X_t = 0.9014 + 1.4151t + Y_t
$$

$$
Y_t = 0.9564Y_{t-1} + W_t
$$

$$
W_t \sim N(0, 4.343)
$$

```{r}
stochastic_fit <- aus_airpassengers |>
  model(stochastic = ARIMA(Passengers ~ pdq(d = 1) + 1))

stochastic_fit |>
  report()
```

We have

$$
(I-B)X_t = W_t + 1.4191
$$

Letting $Y_t = \sum_{s=1}^t W_s$, we get

$$
X_t = X_0 + 1.4191t + Y_t
$$

$$
Y_t = Y_{t-1} + W_t
$$

$$
W_t \sim N(0, 4.271)
$$

The two models look similar. The stochastic trend model allows the "noise" around the trend to be non-stationary, i.e. be a random walk, hence, the time series can deviate far from the trend, even though that is the time series mean.

```{r}
aus_airpassengers |>
  model(stochastic = ARIMA(Passengers ~ pdq(d = 1) + 1),
        deterministic = ARIMA(Passengers ~ trend() + 1 + pdq(d = 0))) |>
  forecast(h = 50) |>
  autoplot(aus_airpassengers, level = 95)
```

Should use stochastic trend when we are not sure that the trend is reliable.

------------------------------------------------------------------------

## 4. Seasonal ARIMA

a.  Consider the seasonal naive model $X_t = X_{t-m} + W_t$. Does this have a unit root?

b.  After taking a first (non-seasonal) difference, what equation does the differenced time series satisfy? Does it have a unit root? Is it stationary?

c.  To verify your conclusions in b), simulate from such a model and plot the differenced time series.

d.  Argue why seasonal non-stationarity should not be tested using unit roots.

e.  What does the `fable` package use to decide seasonal differences? Check the documentation of the function `unitroot_nsdiffs()`.

------------------------------------------------------------------------

Yes, the AR polynomial is

$$
\phi(z) = 1-z^m = (1-z)(1+z+\cdots z^{m-1}).
$$

Hence, $z=1$ is a root (alternatively, we could have just checked $\phi(1) - 0$.

If $Y_t = (I-B)X_t$, then $(Y_t)$ satisfies $Y_t = Y_{t-1} + \cdots + Y_{t-m+1} + W_t$.

Its AR polynomial is $\zeta(z) = 1+z + \cdots + z^{m-1}$, which does not have a unit root. However, its roots are all complex numbers with absolute value equal to 1. Hence, $(Y_t)$ is not stationary.

```{r}
wn <- rnorm(200)
x <- NULL
for (i in 1:200) {
  prev_val <- ifelse(i > 4, x[[i - 4]], 0)
  x <- c(x, prev_val + wn[[i]])
}
snaive_dat <-
  tibble(t = 1:200,
         x = x) |>
  as_tsibble(index = t)
snaive_dat |> 
  mutate(y = difference(x, 1)) |> autoplot(y)
```

Even if the seasonal AR polynomial has a unit root, this would imply that the entire AR polynomial has a unit root. We hence cannot distinguish between whether we have "seasonal" non-stationarity or "non-seasonal" non-stationarity using unit roots alone.

------------------------------------------------------------------------

## 5. Unit root tests at scale (Textbook 13.4.5)

The `aus_livestock` dataset contains time series of meat production in Australia for different animals.

a.  Use `features` together with `unitroot_kpss`, `unitroot_ndiffs`, and `unitroot_nsdiffs` to simultaneously obtain test statistic values, etc. for all time series for `Calves`.

b.  Plot the log transform of the time series corresponding to Queensland, Tasmania, and Victoria between 2005 Jan and 2015 Jan.

------------------------------------------------------------------------

The `feasts` package allows us to compute these tests efficiently at scale.

```{r}
aus_livestock |>
    filter(Animal == "Calves") |>
    features(Count, c(unitroot_kpss, unitroot_ndiffs, unitroot_nsdiffs))
```

Note that `aus_livestock` is a quarterly time series dataset recording the number of each type of livestock animal in Australia, stratified by state. Here, we focus on the time series measuring the number of calves and have computed the KPSS test statistic and p-value. `unitroot_ndiffs` calculates the appropriate number of first differences based on this value, while `unitroot_nsdiffs` calculates the appropriate number of seasonal differences based on the "strength of seasonality" statistic.

Let us do a time plot to get further intuition for these numbers. For ease of interpretation, we only plot values between January 2005 and January 2015 and for the log counts in 3 states: Queensland, Tasmania, and Victoria.

```{r}
#| fig-cap: The log counts of the number of calves in Queensland, Tasmania and Victoria.
#| label: fig-arima-unitroot-plots
aus_livestock |>
    filter(Animal == "Calves", State %in% c("Victoria", "Tasmania", "Queensland")) |>
    filter_index("2005 Jan" ~ "2015 Jan") |>
    select(Month, State, Count) |>
    autoplot(log(Count))
```

We see that the Queensland time series does not have any seasonality but has a non-stationary level. Next, the Tasmania time series has non-stationary seasonality but its level seems stationary. Finally, the Victoria time series has both non-stationary seasonality as well as a non-stationary level.
